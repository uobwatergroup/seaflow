{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a2fb33",
   "metadata": {},
   "source": [
    "# Seasonal Flow Forecasts (SFFs) simulation\n",
    "\n",
    "\n",
    "\n",
    "Now, we conduct the hydrological forecasts uising Tank model and Seasonal Meteorological Forecasts (SMFs) datasets. This code incorpolates the functions below;\n",
    "\n",
    "\n",
    "1. <b> [SMFs data generation] </b> Create csv format files combining each ensemble data (precipitation, temperature and evapotranspiration) and convert csv file to the text format which is readable in the Tank model\n",
    "\n",
    "\n",
    "2. <b> [Tank input data generation </b> Generate the input file of tank model using already estimated parameter and other details, then combine them with SMFs (.txt) data created by the process #1.\n",
    "\n",
    "\n",
    "3. <b> [Run Tank model] </b> Create batch file for multiple simulation and run.\n",
    "\n",
    "\n",
    "4. <b> [Output data management] </b> Collect the simulated flow data and save it as csv format. Then integrate the ensemble data at each month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180a4c3",
   "metadata": {},
   "source": [
    "### 1. SMFs data preparation via  SEAFORM \n",
    "\n",
    "Please note that, before we start SFFs (Seasonal Flow Forecasts) simulation, seasonal precipitation (tp; total precipitation), temperature (t2m; 2m temperature) and evapotranspiration (ET; evaporation) forecasts datasets are required as input of hydrological model (Tank). SMFs data management incluing data download, time series generation and bias correction is readily availabe vias our SEAFORM package (SEAsonal FORcast Managment tool, https://github.com/uobwatergroup/seaform.git).\n",
    "\n",
    "1. Download seasonal forecasts data (p, t, ET) from Copernicus CDS for certain forecasting centre. (SEAFORM module A)\n",
    "2. Generate daily time series data for each month. (SEAFORM module B)\n",
    "3. Apply linear scaling, and generate bias corrected time series. (SEAFORM module C)\n",
    "\n",
    "Place the managed SMFs datasets in relevant folder (original and biascorrected data, refer to the folder path detail shown below '3. Simulation settings')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a52f7e",
   "metadata": {},
   "source": [
    "### 2. Import libraries\n",
    "Now, we need to import the necessary libraries and tools (ðŸš¨ in order to run the code like in the box below, place the mouse pointer in the cell, then click on â€œrun cellâ€ button above or press shift + enter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34bfc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3493c5e1",
   "metadata": {},
   "source": [
    "### 3. Simulation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bb8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_center = 'ECMWF'\n",
    "\n",
    "# Assign working directory and time series data\n",
    "path = os.getcwd()\n",
    "\n",
    "# Input simulation information\n",
    "catchment_name = 'A'\n",
    "ratio = {'A':0.23, 'B':0.605}         # This ratio represent Loss/PET and manually (see hydrologic_data.xlsx)\n",
    "area = {'A':2073.0, 'B':1584.0}       # Catchment area (square kilometers)\n",
    "sim_title = catchment_name + '_SFFs'\n",
    "loss_et_ratio = ratio[catchment_name]\n",
    "catch_area =  area[catchment_name]\n",
    "\n",
    "warmup_year = 2009  # model warm up start year (model will start to run from this year Janurary first)\n",
    "\n",
    "start_year = 2011\n",
    "start_month = 1\n",
    "start_day = 1\n",
    "start_date = str(start_month).zfill(2) + '/' + str(start_day).zfill(2) + '/' + str(start_year)\n",
    "end_year = 2020\n",
    "end_month = 12\n",
    "end_day = 31\n",
    "end_date = str(end_month).zfill(2) + '/' + str(end_day).zfill(2) + '/' + str(end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592e447",
   "metadata": {},
   "source": [
    "### 4. Tank model input file generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446ebca",
   "metadata": {},
   "source": [
    "#### 4.1. Read basic input file from ESP\n",
    "\n",
    "Basic input file (without hydrological data) are the same as ESP, therefore, we just need to bring them to the SFFs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd74f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for num in range(1,13):\n",
    "    for year in range(start_year, end_year+1):\n",
    "        for month in range(start_month, end_month+1):\n",
    "            esp = path + '/analysis/3.ESP/1_input/' + catchment_name + '_' + str(year) + '_' + str(month).zfill(2) + '.txt'\n",
    "            sffs = path + '/analysis/4.SFFs/1_input/'\n",
    "            shutil.copy2(esp, sffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca244b",
   "metadata": {},
   "source": [
    "#### 4.2. Generation of Seasoanl Meteorological Forecasts ensemble\n",
    "\n",
    "Create hydrological ensemble of precipitation, temperature, ET and observed flow data. Hydrological data of each catchment is shown in /data/ folder. We generate this ensemble scenario every month with multiple SMFs timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ffd39f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble datasets for SFFs Monthly ESP are created!\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "folder = {1:'original',2:'biascorrected'}\n",
    "\n",
    "for bc_type in range(1,3):                        # bias correction type {1:'before_bc',2:'after_bc'}\n",
    "    for year in range(start_year, end_year+1):\n",
    "        for month in range(start_month, end_month+1):\n",
    "            # specify the number of ensemble of each forecasting centre\n",
    "            # refer to the ensemble size and data availability\n",
    "            if year > 2016 :\n",
    "                ens_num = 51\n",
    "            else :\n",
    "                ens_num = 25\n",
    "            # add '_bc' if the data is bias corrected\n",
    "            if bc_type == 2:\n",
    "                tail = '_bc'\n",
    "            else :\n",
    "                tail = ''\n",
    "            # read seasonal forecasts data\n",
    "            tp = pd.read_csv(path + '/data/SMFs/' + forecast_center + '/' + folder[bc_type] + '/tp/' + catchment_name + '_' \n",
    "                             + str(year) + '_' + str(month).zfill(2) + '_' + forecast_center.lower() + '_tp' + tail + '.csv')\n",
    "            t2m = pd.read_csv(path + '/data/SMFs/' + forecast_center + '/' + folder[bc_type] + '/t2m/' + catchment_name + '_' \n",
    "                              + str(year) + '_' + str(month).zfill(2) + '_' + forecast_center.lower() + '_t2m' + tail + '.csv')\n",
    "            et = pd.read_csv(path + '/data/SMFs/' + forecast_center + '/' + folder[bc_type] + '/et/' + catchment_name + '_' \n",
    "                             + str(year) + '_' + str(month).zfill(2) + '_' + forecast_center.lower() + '_et' + tail + '.csv')\n",
    "            # Date format change\n",
    "            tp['time2'] = pd.to_datetime(tp['time'], infer_datetime_format=True).dt.strftime(\"%Y-%m-%d\")\n",
    "            # Save the date data as merged\n",
    "            merged = pd.DataFrame(data=tp['time2']).rename(columns = {'time2':'time'})\n",
    "\n",
    "            for i in range(0,ens_num):         # iteration for all ensemble members\n",
    "            \n",
    "                name = 'sc_' + str(i)\n",
    "                merged['prec'] = round(tp[name],2)                # allocate precipitation column\n",
    "                merged['prec'][merged['prec'] < 0] = 0            # correct negative precipitation data\n",
    "                merged['ET'] = round(et[name],2)                  # allocate ET column\n",
    "                merged['temp'] = round(t2m[name],2)               # allocate temperature column\n",
    "                \n",
    "                date = list(merged['time'])\n",
    "                rain = list(merged['prec'])\n",
    "                ET = list(merged['ET'])\n",
    "                temp = list(merged['temp'])\n",
    "\n",
    "                file = open(path + '/analysis/4.SFFs/2_ensemble/' + folder[bc_type] +'/' + catchment_name + '_' + str(year) + '_' + str(month).zfill(2) + '_' + str(i) + '.txt', \"w\")\n",
    "        \n",
    "                for index in range(len(merged)):\n",
    "                       file.write(str(date[index]).rjust(10) + str(rain[index]).rjust(10) + str(ET[index]).rjust(20) \n",
    "                                  + str(temp[index]).rjust(10) + \"\\n\")\n",
    "                file.close()\n",
    "print('Ensemble datasets for SFFs Monthly ESP are created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922c8dfa",
   "metadata": {},
   "source": [
    "#### 4.3. Combine the basic input (from 4.1) and ensemble data (from 4.2)\n",
    "\n",
    "This code enables the combination between the basic simulation input file generated from process 4.1 and ensemble data from process 4.2. When you run this code, you can get the acutal input files for Tank model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb852456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, Tank model input files are generated.\n"
     ]
    }
   ],
   "source": [
    "folder = {1:'original',2:'biascorrected'}\n",
    "\n",
    "for bc_type in range(1,3):\n",
    "    for month in range(start_month, end_month+1):\n",
    "        for year in range(start_year, end_year+1):\n",
    "    \n",
    "            data = data2 = \"\"\n",
    "\n",
    "            if year > 2016 : \n",
    "                lim = 51\n",
    "            else :\n",
    "                lim = 25\n",
    "        \n",
    "            for scenario in range(0, lim):\n",
    "  \n",
    "        # Reading data from file1\n",
    "                with open(path + '/analysis/4.SFFs/1_input/' + catchment_name + '_' + str(year) + '_' + str(month).zfill(2) + '.txt') as fp:\n",
    "                    data = fp.read()\n",
    "  \n",
    "                with open(path + '/analysis/4.SFFs/2_ensemble/' + folder[bc_type] +'/' + catchment_name + '_' + str(year) + '_' + str(month).zfill(2) + '_' + str(scenario) + '.txt') as fp:\n",
    "                    data2 = fp.read()\n",
    "  \n",
    "                data += data2\n",
    "  \n",
    "                with open (path + '/analysis/4.SFFs/3_run/' + folder[bc_type] +'/' + catchment_name + '_' + str(year) + '_' + str(month).zfill(2) + '_' + str(scenario) + '.txt', 'w') as fp:\n",
    "                    fp.write(data)\n",
    "print('Now, Tank model input files are generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e72696",
   "metadata": {},
   "source": [
    "### 5. Run Tank model\n",
    "\n",
    "Input data for the SFFs simulation has created, and now we run the Tank model for each scenario. For the simulation, 'Sim_SMTank.exe' file should exist in '4.SFFs/3_run' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8c6ca",
   "metadata": {},
   "source": [
    "#### 5.1 Batch file generation for the multiple simulation\n",
    "\n",
    "To run the Tank model with multiple scenarios, this code generates the batch file. We define model name and input and out file names in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ab9d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = {1:'original',2:'biascorrected'}\n",
    "\n",
    "# allocate the input and output file names\n",
    "for bc_type in range(1,3):     #bias correction type : original (non-bias corrected), biascorrected\n",
    "    \n",
    "    bat_file = open(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/run_sffs.bat', \"w\")\n",
    "    \n",
    "    for year in range(start_year, end_year +1):\n",
    "        for month in range(1, 13):\n",
    "            if year > 2016 : \n",
    "                lim = 51    # Number of ensemble after 2017\n",
    "            else :\n",
    "                lim = 25    # Number of ensemble before 2017\n",
    "        \n",
    "            for scenario in range(0, lim):\n",
    "                bat_file.write(str('Sim_SMTank') + \" \" + catchment_name + '_' + str(year) + '_' + str(month).zfill(2) \n",
    "                               + '_' + str(scenario) + '.txt' + \" \" + catchment_name + '_' + str(year) + '_' \n",
    "                               + str(month).zfill(2) + '_' + str(scenario) + '.out'+ \"\\n\")\n",
    "bat_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101012c",
   "metadata": {},
   "source": [
    "#### 5.2 Execute batch file to run Tank model\n",
    "\n",
    "Now, we run the Tank model using batch file that we have just made. If your are working with multiple years and months, it will take quite long time to terminate the whole simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1364a28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tank model simulation has completed!\n"
     ]
    }
   ],
   "source": [
    "# set working directory and batch file\n",
    "\n",
    "for bc_type in range(1,3):\n",
    "    workingDir = (path + '/analysis/4.SFFs/3_run/' + folder[bc_type])\n",
    "    executeFile = (path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/run_sffs.bat')\n",
    "\n",
    "    def run(path):\n",
    "        os.chdir(workingDir)\n",
    "        os.system(path)\n",
    "    run(executeFile)\n",
    "\n",
    "print('Tank model simulation has completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23bdc5f",
   "metadata": {},
   "source": [
    "### 6. Result data management\n",
    "\n",
    "Simulation for ESP has terminated, and now it is time to manage the output data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44568a81",
   "metadata": {},
   "source": [
    "#### 6.1 Select simulated flow data form output files\n",
    "\n",
    "Output file contains diverse kinds of information such as precipitation, temperature and simulated flow. What we need is date and simulated flow. This code enables simulated flow data selection and add date information, then save the selected data to a csv file format.\n",
    "\n",
    "Note that, the unit of simulated flow is Cubic Meters per Second (CMS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1943634a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data selection is completed!\n"
     ]
    }
   ],
   "source": [
    "for bc_type in range(1,3):\n",
    "    for year in range(start_year, end_year+1):\n",
    "        for month in range(start_month,end_month+1):\n",
    "        \n",
    "            if year > 2016 : \n",
    "                lim = 51\n",
    "            else :\n",
    "                lim = 25\n",
    "                \n",
    "            for scenario in range(0, lim):\n",
    "                # calculate data gap between the warm up start date and the start of simulation\n",
    "                gap = datetime.datetime(year, month, 1) - datetime.datetime(int(warmup_year), 1, 1)\n",
    "                # select the column range (horizontal) for simulated flow data (No need to change this)\n",
    "                colspecs = [(55,64)]\n",
    "                # select the simulated flow data excluding the unnecessary rows (No need to chang this)\n",
    "                data_sel = pd.read_fwf(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/' + catchment_name + '_' \n",
    "                                       + str(year) +  '_' + str(month).zfill(2) +  '_'  + str(scenario) + '.out', \n",
    "                                       skiprows=48+gap.days, skipfooter=41, colspecs=colspecs, \n",
    "                                       names=['Q_sim_' + str(scenario)])\n",
    "                # allocate date\n",
    "                index=pd.date_range(datetime.datetime(year, month, 1), periods=len(data_sel)) \n",
    "                data_sel['date'] = index\n",
    "                data_sel = data_sel.set_index('date').reset_index()\n",
    "                # save the selected data as csv format\n",
    "                new_csv_file = data_sel.to_csv(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/' + catchment_name + '_' \n",
    "                                               + str(year) +  '_' + str(month).zfill(2) +  '_'  + str(scenario) + '.csv')\n",
    "print('Data selection is completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b1391",
   "metadata": {},
   "source": [
    "#### 6.2 Monthly ensemble integration\n",
    "\n",
    "By the previous process, we generated the ensemble of simulated flow for each month. However, there are too many datasets to deal with and it is not efficient to manage the data. Therefore, we need to integrate every ensemble at each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee874f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bc_type in range(1,3):\n",
    "    for year in range(start_year, end_year+1):\n",
    "        for month in range(start_month, end_month+1):\n",
    "            # read the observed flow data to insert in the dataset we are going to generate\n",
    "            obs_flow = pd.read_csv(path + '/data/' + catchment_name + '_hydrologic_data.csv')\n",
    "            obs_flow['date'] = obs_flow['date'].astype('datetime64[ns]')    # date type\n",
    "        \n",
    "            # read the first year (same as scenario 0) data to use it as the first column\n",
    "            df_head = pd.read_csv(path + '/analysis/4.SFFs/3_run/'  + folder[bc_type] + '/' + catchment_name + '_' + str(year) \n",
    "                                  +  '_' + str(month).zfill(2) + '_' + str(0) + '.csv')\n",
    "            df_head['date'] = df_head['date'].astype('datetime64[ns]')\n",
    "            # insert lead time column\n",
    "            df_head['leadtime'] = df_head['date'].dt.month - month + 1 + 12 * (df_head['date'].dt.year - year)\n",
    "            df_head = df_head.iloc[:, [0,1,3,2]]\n",
    "\n",
    "            if year > 2016 : \n",
    "                lim = 51\n",
    "            else :\n",
    "                lim = 25\n",
    "            # fill the next year's ensemble next to the previous column\n",
    "            for scenario in range(1, lim):\n",
    "                # read simulated flow data one by one \n",
    "                df = pd.read_csv(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/' + catchment_name + '_' + str(year) \n",
    "                                 +  '_' + str(month).zfill(2) +  '_'  + str(scenario) + '.csv')\n",
    "                df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True, format='%m/%d/%Y', errors='ignore')\n",
    "                df_head[scenario] = df.iloc[:,2]\n",
    "                   \n",
    "            del df_head['Unnamed: 0'] # delete unnecessary column \n",
    "            df_head.rename(columns = {'Q_sim_0':0},inplace=True)               # simplify the column name\n",
    "            # insert forecasted mean column\n",
    "            df_head['mean'] = round(df_head.loc[:,0:].mean(axis=1),2)\n",
    "            # insert observed flow column\n",
    "            df_head['obs'] = np.nan                                            # Insert observed data (time consuming)\n",
    "            df_head['obs'] = np.where(df_head['obs'].isna(), df_head['date'].map(obs_flow.set_index('date')['obs_flow']), df_head['obs'])    # observed data referencing\n",
    "            df_head.set_index('date', inplace=True)\n",
    "            # save the integrated ESP ensemble datasets to csv format\n",
    "            df_head.to_csv(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/[out]' + catchment_name +  '_' + str(year) \n",
    "                           +  '_' + str(month).zfill(2) + '.csv')\n",
    "print('Monthly SFFs simulation ensemble datasets are created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8349e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
