{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a2fb33",
   "metadata": {},
   "source": [
    "# Skill assessment (CRPS calculations)\n",
    "\n",
    "Since the seasonal forecasts are comprised of ensemble members, generally applied simple evaluation methods such as RMSE (Root Mean Squared Error) and R2 have limitations. \n",
    "Thus, in this code, CRPS or CRPSS are adopted to measure the skill of ensembled datasets.\n",
    "This code enables you to calculate those indices automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ec6c3",
   "metadata": {},
   "source": [
    "## 1. Import libraries\n",
    "Now, we need to import the necessary libraries and tools (ðŸš¨ in order to run the code like in the box below, place the mouse pointer in the cell, then click on â€œrun cellâ€ button above or press shift + enter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b01864a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import hydrostats.ens_metrics as em"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1452353",
   "metadata": {},
   "source": [
    "## 2. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "026c9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forecast provider\n",
    "forecast_center = 'ECMWF'\n",
    "\n",
    "# Assign working directory and time series data\n",
    "path = os.getcwd()\n",
    "\n",
    "# Input simulation information\n",
    "catchment_name = 'A'\n",
    "start_year = 2011\n",
    "start_month = 1\n",
    "start_day = 1\n",
    "start_date = str(start_month).zfill(2) + '/' + str(start_day).zfill(2) + '/' + str(start_year)\n",
    "end_year = 2020\n",
    "end_month = 12\n",
    "end_day = 31\n",
    "end_date = str(end_month).zfill(2) + '/' + str(end_day).zfill(2) + '/' + str(end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f671b56",
   "metadata": {},
   "source": [
    "##  3. Rearrange Datasets\n",
    "\n",
    "Basically, CRPS/CRPSS are calculated according to lead time. Therefore, we need to collect them into a single file for each lead time. This code enable to collect every data having same lead time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93bf98",
   "metadata": {},
   "source": [
    "### 3.1 ESP ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc616868",
   "metadata": {},
   "outputs": [],
   "source": [
    "for leadtime in range(1, 8):  # Loop over lead times from 1 to 7 months\n",
    "    for year in range(start_year, end_year + 1):  # Loop over years\n",
    "        for month in range(start_month, end_month + 1):  # Loop over months within the specified range\n",
    "\n",
    "            # Read ESP simulation results for the current year and month\n",
    "            df = pd.read_csv(path + '/analysis/3.ESP/3_run/[out]' + catchment_name + '_' + str(year) + '_' \n",
    "                             + str(month).zfill(2) + '.csv')\n",
    "\n",
    "            # Calculate cumulative sum of mean values grouped by lead time\n",
    "            df2 = df.groupby(by=['leadtime']).mean().cumsum()\n",
    "\n",
    "            # Create a 'date' column containing the current year and month\n",
    "            df2['date'] = str(year) + '_' + str(month)\n",
    "\n",
    "            # Rearrange column order with 'date' as the first column\n",
    "            col1 = df2.columns[-1:].to_list()\n",
    "            col2 = df2.columns[:-1].to_list()\n",
    "            new_col = col1 + col2\n",
    "            df3 = df2[new_col]\n",
    "\n",
    "            # Extract data for the current lead time and transpose it\n",
    "            temp = pd.DataFrame(df3.loc[leadtime]).T\n",
    "\n",
    "            # Stack data for the first iteration of the outer loop (initialize temp1)\n",
    "            if year == int(start_year) and month == int(start_month):\n",
    "                temp1 = temp\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # Concatenate current iteration's data with existing temp1 DataFrame\n",
    "            temp1 = pd.concat([temp1, temp], axis=0, ignore_index=True)\n",
    "\n",
    "    # Remove the first row (header) and set 'date' as the index\n",
    "    temp1 = temp1.iloc[1:]\n",
    "    temp1.set_index('date', inplace=True)\n",
    "\n",
    "    # Save the aggregated data to a CSV file under the 'skill' directory for each lead time\n",
    "    temp1.to_csv(path + '/analysis/3.ESP/3_run/skill/' + catchment_name + '_' + str(leadtime) + '_esp.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063970a",
   "metadata": {},
   "source": [
    "### 3.2 SFFs ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e123cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = {1: 'original', 2: 'biascorrected'}\n",
    "\n",
    "for bc_type in range(1, 3):  # Loop through bias correction types (1 for original, 2 for bias corrected)\n",
    "    for leadtime in range(1, 8):  # Loop through lead times from 1 to 7 months\n",
    "        for year in range(start_year, end_year + 1):  # Loop through years within the specified range\n",
    "            for month in range(start_month, end_month + 1):  # Loop through months within the specified range\n",
    "                \n",
    "                # Read seasonal hydrological forecasts results from CSV files\n",
    "                df = pd.read_csv(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/[out]' + catchment_name + '_' \n",
    "                                 + str(year) + '_' + str(month).zfill(2) + '.csv')\n",
    "\n",
    "                # Calculate cumulative sum of mean values grouped by lead time\n",
    "                df2 = df.groupby(by=['leadtime']).mean().cumsum()\n",
    "\n",
    "                # Create a 'date' column containing the current year and month\n",
    "                df2['date'] = str(year) + '_' + str(month)\n",
    "\n",
    "                # Rearrange column order with 'date' as the first column\n",
    "                col1 = df2.columns[-1:].to_list()\n",
    "                col2 = df2.columns[:-1].to_list()\n",
    "                new_col = col1 + col2\n",
    "                df3 = df2[new_col]\n",
    "\n",
    "                # Extract data for the current lead time and transpose it\n",
    "                temp = pd.DataFrame(df3.loc[leadtime]).T\n",
    "\n",
    "                # Stack data for the first iteration of the outer loop (initialize temp1)\n",
    "                if year == int(start_year) and month == int(start_month):\n",
    "                    temp1 = temp\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                # Concatenate current iteration's data with existing temp1 DataFrame\n",
    "                temp1 = pd.concat([temp1, temp], axis=0, ignore_index=True)\n",
    "\n",
    "        # Remove the first row (header) and rename columns 'mean2' and 'obs2' to 'mean' and 'obs'\n",
    "        temp1 = temp1.iloc[1:]\n",
    "        temp1['mean2'] = temp1['mean']\n",
    "        temp1['obs2'] = temp1['obs']\n",
    "        temp1 = temp1.drop(['mean', 'obs'], axis=1)\n",
    "        temp1.rename(columns={'mean2': 'mean', 'obs2': 'obs'}, inplace=True)\n",
    "\n",
    "        # Set 'date' as the index and save the aggregated data to a CSV file under the 'skill' directory\n",
    "        temp1.set_index('date', inplace=True)\n",
    "        temp1.to_csv(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/skill/' + catchment_name + '_' \n",
    "                     + str(leadtime) + '_' + folder[bc_type] + '_sffs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626673c",
   "metadata": {},
   "source": [
    "## 4. Calculate CRPS at each lead time\n",
    "\n",
    "CRPS is a measure of how good forecasts are in matching observed outcomes considering each ensemble. It is a quadratic measure of the difference between the forecast cumulative distribution function (CDF) and the reference dataset of the observation (Zamo and Naveau, 2017). The CRPS is thus calculated as\n",
    "\n",
    "$$ CRPS= \\int [F(x) - H(x > y)]^2 dx $$\n",
    "\n",
    "where F(x) represents the cumulative distribution of seasonal forecasts, y is observed precipitation, H is called the indicator function which is equals to 1 when x > y and 0 when x < y. Once the CRPS is equals to 0, the forecast is wholly accurate, conversely, the higher the CRPS, the worse the performance of the forecast. \n",
    "\n",
    "Also, sometimes we can face the issue from the number of ensemble members. Most of originating centres have changed number of ensemble members once. (Please see A.Download seasonal forecasts datasets / 3. Seasonal forecasts systems and datasets for 8 originating centres / Total precipitation table). In this case, we need to designate exact location and number of ensemble manually. \n",
    "\n",
    "This example show you the case when we apply ECMWF datasets to calculate CRPS from 2011 to 2020. In this case, there are 25 ensemble members and 72 rows from Jan.2011 to Dec.2016, also rest of the data have 51 ensemble members. If the number of ensemble members is same, you can put the same number on it.  <font color='red'> Please note that, you need to manually revise some of the code below;</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea64c32",
   "metadata": {},
   "source": [
    "### 4.1 CRPS of ESP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c5d1b6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The skill (CRPS) of ESP is computed\n"
     ]
    }
   ],
   "source": [
    "for leadtime in range(1, 8):\n",
    "    # read ESP data rearranged by lead times\n",
    "    df = pd.read_csv(path + '/analysis/3.ESP/3_run/skill/' + catchment_name + '_' + str(leadtime) + '_esp.csv')\n",
    "    \n",
    "    # Convert DataFrame to numpy array and convert data to float\n",
    "    df_a = df.to_numpy().astype(float)\n",
    "    \n",
    "    # Select ensemble data only from the numpy array\n",
    "    df_a2 = df_a[:, 1:df_a.shape[1] - 2]\n",
    "    \n",
    "    # Select the column for observed data from the numpy array\n",
    "    df_obs = df_a[:, len(df.columns) - 1]\n",
    "    \n",
    "    # Calculate CRPS (Continuous Ranked Probability Score) using observed and ensemble data\n",
    "    crps_dictionary_rand1 = em.ens_crps(df_obs, df_a2)\n",
    "    crps = crps_dictionary_rand1['crps']\n",
    "    \n",
    "    # Create a DataFrame from CRPS values\n",
    "    csv = pd.DataFrame(crps)\n",
    "    \n",
    "    # Extract month from 'date' column and add it as a new column 'month'\n",
    "    csv['month'] = df['date'].str.slice(start=5, stop=7)\n",
    "    \n",
    "    # Set 'date' as the index of the DataFrame csv\n",
    "    csv.set_index(df['date'], inplace=True)\n",
    "    \n",
    "    # Rename the CRPS column to 'CRPS'\n",
    "    csv = csv[['month', 0]]\n",
    "    csv = csv.rename(columns={0: 'CRPS'})\n",
    "    \n",
    "    # Add 'leadtime' column to csv DataFrame\n",
    "    csv['leadtime'] = leadtime\n",
    "    \n",
    "    # Stack data: initialize temp DataFrame with csv in the first iteration\n",
    "    if leadtime == 1:\n",
    "        temp = csv\n",
    "    else:\n",
    "        temp = pd.concat([temp, csv])\n",
    "\n",
    "# Select columns 'month', 'leadtime', and 'CRPS' from temp DataFrame\n",
    "temp = temp[['month', 'leadtime', 'CRPS']]\n",
    "\n",
    "# Save the results to a CSV file under the 'skill' directory for ESP\n",
    "temp.to_csv(path + '/analysis/3.ESP/3_run/skill/[skill]' + catchment_name + '_esp.csv')\n",
    "\n",
    "print('The skill (CRPS) of ESP is computed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d9fb7",
   "metadata": {},
   "source": [
    "### 4.2 CRPS of SFFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7b4cb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The skill (CRPS) of SFFs has computed.\n"
     ]
    }
   ],
   "source": [
    "import hydrostats.ens_metrics as em   # Import library for calculating CRPS\n",
    "folder = {1: 'original', 2: 'biascorrected'}\n",
    "\n",
    "# Should be manually revised (This is an example of ECMWF)) \n",
    "num_row = 72     # The number of rows for the first datasets having 'num_col1' of ensemble members\n",
    "num_col1 = 25    # The number of ensemble members for the first datasets\n",
    "num_col2 = 51    # The number of ensemble members for the second datasets\n",
    "\n",
    "for bc_type in range(1, 3):\n",
    "    for leadtime in range(1, 8):\n",
    "        # Read SFFs data rearranged by lead times\n",
    "        df = pd.read_csv(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/skill/' + catchment_name + '_' \n",
    "                         + str(leadtime) + '_' + folder[bc_type] + '_sffs.csv')\n",
    "        \n",
    "        # Convert DataFrame to numpy array and convert data to float\n",
    "        df_a = df.to_numpy().astype(float)\n",
    "        \n",
    "        # Select ensemble data only\n",
    "        df_a2 = df_a[:, 1:df_a.shape[1] - 2]\n",
    "        \n",
    "        # Select ensemble data having 25 ensembles (~ Dec. 2016)\n",
    "        df_a3 = df_a2[:num_row, :num_col1]\n",
    "        \n",
    "        # Select ensemble data having 51 ensembles (Jan. 2017 ~)\n",
    "        df_a4 = df_a2[num_row:, :num_col2]\n",
    "        \n",
    "        # Select the column for observed data having 25 ensembles (~ Dec. 2016)\n",
    "        df_obs1 = df_a[:num_row, len(df.columns) - 1]\n",
    "        \n",
    "        # Select the column for observed data having 51 ensembles (Jan. 2017 ~)\n",
    "        df_obs2 = df_a[num_row:, len(df.columns) - 1]\n",
    "        \n",
    "        # Calculate CRPS using observed and ensemble data\n",
    "        crps_dictionary_rand1 = em.ens_crps(df_obs1, df_a3)\n",
    "        crps_dictionary_rand2 = em.ens_crps(df_obs2, df_a4)\n",
    "        \n",
    "        # Extract CRPS values\n",
    "        temp1 = crps_dictionary_rand1['crps']\n",
    "        temp2 = crps_dictionary_rand2['crps']\n",
    "        \n",
    "        # Concatenate CRPS values along axis 0 (vertically)\n",
    "        crps = np.concatenate([temp1, temp2], axis=0)\n",
    "        \n",
    "        # Create a DataFrame from CRPS values\n",
    "        csv = pd.DataFrame(crps)\n",
    "        \n",
    "        # Extract month from 'date' column and add it as a new column 'month'\n",
    "        csv['month'] = df['date'].str.slice(start=5, stop=7)\n",
    "        \n",
    "        # Add 'date' column to csv DataFrame\n",
    "        csv['date'] = df['date']\n",
    "        \n",
    "        # Set 'date' as the index of the DataFrame csv\n",
    "        csv.set_index(csv['date'], inplace=True)\n",
    "        \n",
    "        # Select columns 'month' and CRPS from csv DataFrame\n",
    "        csv = csv[['month', 0]]\n",
    "        csv = csv.rename(columns={0: 'CRPS'})\n",
    "        \n",
    "        # Add 'leadtime' column to csv DataFrame\n",
    "        csv['leadtime'] = leadtime\n",
    "        \n",
    "        # Stack data: initialize temp DataFrame with csv in the first iteration\n",
    "        if leadtime == 1:\n",
    "            temp = csv\n",
    "        else:\n",
    "            temp = pd.concat([temp, csv])\n",
    "    \n",
    "    # Select columns 'month', 'leadtime', and 'CRPS' from temp DataFrame\n",
    "    temp = temp[['month', 'leadtime', 'CRPS']]\n",
    "    \n",
    "    # Save the results to a CSV file under the 'skill' directory for SFFs\n",
    "    temp.to_csv(path + '/analysis/4.SFFs/3_run/' + folder[bc_type] + '/skill/[skill]' + catchment_name \n",
    "                + '_' + folder[bc_type] + '_sffs.csv')\n",
    "    \n",
    "# Print a message indicating the completion of CRPS computation for SFFs\n",
    "print('The skill (CRPS) of SFFs has computed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634c62dc",
   "metadata": {},
   "source": [
    "## 5. CRPSS calculation\n",
    "\n",
    "CRPSS compares the skill of seasonal forecasts with climatology, thus finally it can be simply calculated as \n",
    "\n",
    "$$ CRPSS=\\ 1\\ -\\ \\frac{{\\rm CRPS}^{Sys}}{{\\rm CRPS}^{Ref}}$$\n",
    "\n",
    "where $CRPS^{Sys}$ is previously calculated $CRPS$ (seasonal forecasts), $CRPS^{Ref}$ represents the reference $CRPS$ obtained from climatology. When the skill score is higher (lower) than zero, the forecasting system is more (less) skilful than reference. When it is equal to zero, the system (seasonal forecasts) and the reference (Climatology) have equivalent skill. \n",
    "\n",
    "CRPSS can be calculated by runing the code below;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0523f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPSS calculation has completed.\n"
     ]
    }
   ],
   "source": [
    "folder = {1: 'original', 2: 'biascorrected'}\n",
    "\n",
    "for bc_type in range(1, 3):\n",
    "    # read calculated CRPS data (SFFs)\n",
    "    df = pd.read_csv(path + f\"/analysis/4.SFFs/3_run/{folder[bc_type]}/skill/[skill]{catchment_name}_{folder[bc_type]}_sffs.csv\")\n",
    "    \n",
    "    # read reference CRPS data (ESP)\n",
    "    df_ref = pd.read_csv(path + f\"/analysis/3.ESP/3_run/skill/[skill]{catchment_name}_esp.csv\")\n",
    "    \n",
    "    # add reference CRPS column\n",
    "    df['CRPS_ref'] = df_ref['CRPS']\n",
    "    \n",
    "    # add CRPSS column\n",
    "    df['CRPSS'] = 1 - df['CRPS'] / df['CRPS_ref']\n",
    "    \n",
    "    # Initialize 'count' column with zeros\n",
    "    df['count'] = 0\n",
    "    \n",
    "    # Use .loc for assignment based on condition\n",
    "    df.loc[df['CRPSS'] > 0, 'count'] = 1\n",
    "    df.loc[df['CRPSS'] <= 0, 'count'] = 0\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(path + f\"/analysis/4.SFFs/3_run/{folder[bc_type]}/skill/[skill]{catchment_name}_{folder[bc_type]}_sffs.csv\", index=False)\n",
    "\n",
    "print('CRPSS calculation has completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e576ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
